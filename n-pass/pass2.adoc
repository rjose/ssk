= Pass 2: Set up a monitor container

Create a docker container with kibana on it.

Also create a dev container that has a syslog-ng client running
on it. The demo is to log something in the dev container and have it
show up in the kibana UI on the monitor.

The dev containers should be set up so the syslog-ng client sends data
to the monitor node. We'll use docker linking to link the dev
containers with the monitor container. We'll have to assume that the
monitor container will always be running before the dev containers. To
do this, we should create a new make target that spins up a monitor
container and then whatever dev containers we need. This will be a
model for all development going forward (I think).

All dev nodes send syslog-ng messages to monitor:1000.

The monitor node needs to ensure that its /var/log/messages file (or
whatever files it needs to render data) is persisted.


== Tasks
- [x] Create Dockerfile for dev
- [x] Create Dockerfile for monitor
- [x] Spin up monitor and 2 dev containers
- [x] Create syslog-ng messages on each dev container and see it show
  up in the monitor log
- [x] Set up logstash on the monitor node
- [x] Set up kibana on the monitor node
- [x] Send log messages of different levels and see them in kibana
- [x] Filter messages based on log level
- [x] Make monitor log persistent

== Status
- Effort spent: 5.75h
- Effort left: 0h
- Initial estimate: 10h

== Log

=== Saturday, 02/28/2015

----
** 19:55 >> Create Dockerfile for dev
We'll create a subdirectory under docker/base called "dervied" and
copy the old dev Dockerfile into it.

** 20:07 (12 min) Configure syslog-ng
I'm creating the Dockerfile. Let's look closely at the syslog-ng.conf
file and make sure it's simple (and correct). The run file was
constructed by looking at the /etc/service.d script for syslog-ng and
pulling out the relevant pieces.


** 20:25 (30 min) I see why I didn't get the various log levels
There was a filter in the log statement. Duh.

** 20:25 (30 min) Build dev image
Let's build the dev image and see if we can create some log messages.

** 20:31 (36 min) Decided to move all docker images to top level
The nesting just seemed to complicated.

** 20:32 (37 min) Built dev image
Let's give it a spin. Looks like I have an older version of
syslog-ng. Let's try building the image again.

** 20:44 (49 min) Got syslog running
But it's not running as part of runit yet. Also, I don't know how to
see the priority.


** 20:58 (63 min) I understand the syslog config more
I've been looking at /var/log/messages for entries from
"logger". However, these messages are being filtered from s_src by
their level and routed to different files. Since we're not filtering
messages when sending to d_monitor, we should be seeing all messages.

** 21:01 << (66 min) Need to make sure runit starts syslog properly

** 21:03 Take a break
I need to take a closer look at the run script. This seems not to work
via runit. Let's copy the init.d file over for syslog-ng and examine it.

** 22:05 >> Mount current directory into /working
Let's mount the working directory of the dev container into
/working. That will give us a way to copy files.

** 22:13 (8 min) Got the directory mounted
Let's take a look at the syslog-ng file and see what we can pull out.

** 22:37 (32 min) Got syslog running properly
Alright, this looks pretty good. Let's check in. I think we should
have the base container start syslog, though. That way, we'll only
need to copy the syslog-ng.conf file over.

*** TODO Clean up makefile again

** 22:49 (44 min) Cleaned up Dockerfiles
OK, this is much better. The base container doesn't have a valid
syslog-ng configuration, but that's OK for now. I'll fix it later.

*** TODO Add valid config file for sskit/base

** 22:50 (45 min) Let's check in
Let's get these changes in and call it a night.
----

=== Sunday, 03/01/2015

----
** 07:01 >> Set up Dockerfile for monitor
Alright, let's create a new docker image for our monitor.

** 07:07 (6 min) Building the monitor image
OK, this is grabbing a whole bunch of stuff.

** 07:11 (10 min) Error installing openjdk, so retrying
Looks like there was a network issue. It seems to have grabbed what it
needed now.

** 07:14 (13 min) Installed main components
Now, we need to copy some files over. Let's create a to_copy
subdirectory and get things into place.

** 07:22 (21 min) Updated syslog-ng config file
Let's install it and give it a try.

** 07:23 (22 min) Spin up a dev and monitor
I think we'll need a make target for this. I want to spin up two
containers and have them be linked.

** 07:32 (31 min) Messed up the config file
Let's try it again.

** 07:46 << (46 min) Rebuilding again
I updated the base to add "--no-caps" to its startup. No I have to
rebuild monitor.

** 10:08 >> Add config files
Let's configure elasticsearch next.

** 10:13 << (5 min) Copied the elasticsearch.yml file over

** 20:04 >> Set up elasticsearch
Let's copy the config file over and then add it elasticsearch to runit

** 20:15 << (11 min) elasitcsearch is running
Cool. Let's take a quick coffee break and then get logstash running.


** 20:42 >> Get logstash running next
Let's get the config files copied over and make sure they make sense.

** 20:51 (9 min) Have logstash config in place
Let's give it a spin.

** 20:54 (12 min) Logged a message locally and saw it show up.

Let's get kibana running next and then take a break.

** 20:56 (14 min) Need to expose port 9292 for kibana
Let's check the run script I had from before.

** 21:02 (20 min) Kibana is rendering logstash data!

*** TODO Ensure that the /var/log/messages file in monitor is persistent

** 21:04 (22 min) Run dev and try logging message

*** TODO Scrub makefile

** 21:09 (27 min) Can log a message in a dev container and see it show up
The heart of this is basically done. What's missing is getting the
priority of the messages. Let's look into that next.

** 21:11 << (29 min) Let's check in
Let's check in what we have and then scrub the Makefile after a break.
----


=== Monday, 03/02/2015
----

** 16:11 >> Clean up makefile
Let's clean up the makefile and then see if we can spin up 2 dev
containers and 1 monitor.

** 16:15 (4 min) Got messages from each container to the monitor!
Looks good. Got messages from the containers. We need to figure out
how to get the meta data to the containers. For instance, the log
level isn't being captured and the host is being set to the docker
container ID.

** 16:22 (11 min) Priority is being sent
I do see the priority coming through as an integer in angle
brackets. <13> means info; <11> is error <9> is alert. I think this
combines the user facility (being 1) * 8 + the level.

** 16:24 << (13 min) Check in
Let's check in and then take a little break.

** 16:43 >> Make log persistent

** 16:47 (4 min) 

Let's try mounting the working directory into /monitor directory in
the monitor container. We should symlink /var/log/messages to /working

** 16:58 <<(15 min) Logfile is persisted
The logfile is persisted but it's not being read in by logstash. How
do we get it to read the old things, too?

** 17:15 >> Try specifying the the start_position in the logstash config

** 17:17 (2 min) Looks good!

** 17:18 (3 min) Now, let's try to get the priority out.

** 17:39 <<(24 min) The grok patterns for logstash
Here's the URL:
https://github.com/elasticsearch/logstash/blob/v1.4.0/patterns/grok-patterns


Here's a sample log

'Mar  3 00:58:25 172.17.0.109 89 <13>1 2015-03-03T00:58:25+00:00 dev1
logger - - [meta sequenceId="3"] Can you read this?'


** 18:50 >> Let's get the grok pattern correct
This works:

"%{MONTH}%{SPACE}%{MONTHDAY} %{HOUR}:%{MINUTE}:%{SECOND} %{IP:ip} %{POSINT} <%{POSINT:priority}>%{POSINT} %{TIMESTAMP_ISO8601} %{DATA:client_host} %{DATA:app} %{GREEDYDATA:syslog_message}"

** 19:58 << (68 min) Wow, getting that pattern right was hard

** 19:59 Take a break
Let's check in and then take a break. Afterwards, I want to map the
priority to a priority_label.

** 20:05 >> The syslog priorities

   * Debug: 15, user.debug
   * Info: 14, user.info
   * Notice: 13, user.notice
   * Warning: 12, user.warning
   * Error: 11, user.error
   * Critical: 10, user.crit
   * Alert: 9, user.alert
   * Panic: 8, user.panic
   * Emergency: 8, user.emerg

** 20:25 << (20 min) Done
OK, I think we're done with Pass 2!

----
